{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS from tvm, different required packages and the profiling infrastructure\n",
    "\n",
    "from numpy.core.numeric import full\n",
    "import tvm\n",
    "from tvm.contrib import utils, graph_executor as runtime\n",
    "from tvm.relay.op.nn.nn import dense, dilate, conv2d\n",
    "#####\n",
    "import numpy as np\n",
    "import pynvml as nv\n",
    "# from func_timeout import func_timeout\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "#####\n",
    "from components import description_vector as dv\n",
    "from components import serializer\n",
    "from components import profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default figure size\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful to suppress output of debug runtime run function\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 : b'NVIDIA GeForce RTX 3070'\n"
     ]
    }
   ],
   "source": [
    "nv.nvmlInit()\n",
    "deviceCount = nv.nvmlDeviceGetCount()\n",
    "for i in range(deviceCount):\n",
    "    handle = nv.nvmlDeviceGetHandleByIndex(i)\n",
    "    print(\"GPU\", i, \":\", nv.nvmlDeviceGetName(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nvml:::NVIDIA_GeForce_RTX_3070:device_0:power']\n"
     ]
    }
   ],
   "source": [
    "# defining important variables for the profiling system\n",
    "\n",
    "target = \"cuda\"\n",
    "target_class = \"cuda\"\n",
    "\n",
    "device = \"3070\"\n",
    "dev_idx = 0\n",
    "dev = tvm.device(str(\"cuda\"), dev_idx)\n",
    "time_min_res = 0.2\n",
    "\n",
    "\n",
    "state_path = \"./states\"\n",
    "state_file = \"state\"\n",
    "\n",
    "layer_name = \"conv2d\"\n",
    "\n",
    "metrics = profiling.get_metrics(target, device, backend=\"nvml\", dev_idx=dev_idx)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv.nvmlInit()\n",
    "handle = nv.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "#metrics.append(\"nvml:::NVIDIA_GeForce_GTX_980_Ti:device_1:pstate\") #unable to read using TVM PAPI Profiler due to limitation to integer data\n",
    "metrics.append(\"nvml:::NVIDIA_GeForce_RTX_3070:device_\"+str(dev_idx)+\":gpu_utilization\")\n",
    "metrics.append(\"nvml:::NVIDIA_GeForce_RTX_3070:device_\"+str(dev_idx)+\":memory_utilization\")\n",
    "metrics.append(\"nvml:::NVIDIA_GeForce_RTX_3070:device_\"+str(dev_idx)+\":graphics_clock\")\n",
    "metrics.append(\"nvml:::NVIDIA_GeForce_RTX_3070:device_\"+str(dev_idx)+\":sm_clock\")\n",
    "metrics.append(\"nvml:::NVIDIA_GeForce_RTX_3070:device_\"+str(dev_idx)+\":memory_clock\")\n",
    "metrics.append(\"nvml:::NVIDIA_GeForce_RTX_3070:device_\"+str(dev_idx)+\":allocated_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"n\"] = 1\n",
    "config[\"h\"] = 225\n",
    "config[\"w\"] = 225\n",
    "config[\"c\"] = 3\n",
    "config[\"pad\"] = 0\n",
    "config[\"dilation\"] = 1\n",
    "config[\"kernel\"] = 3\n",
    "config[\"strides\"] = 1\n",
    "config[\"grps\"] = 1\n",
    "config[\"channels\"] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:26:35] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:65: Op #0 tvmgen_default_fused_nn_conv2d:\n",
      "[03:26:35] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 0: 22.2101 us/iter\n",
      "[03:26:35] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 1: 22.207 us/iter\n",
      "[03:26:35] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 2: 22.2122 us/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed measurement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:26:42] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:65: Op #0 tvmgen_default_fused_nn_conv2d:\n",
      "[03:26:42] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 0: 21.8625 us/iter\n",
      "[03:26:42] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 1: 21.8639 us/iter\n",
      "[03:26:42] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 2: 21.8725 us/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed measurement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:26:50] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:65: Op #0 tvmgen_default_fused_nn_conv2d:\n",
      "[03:26:50] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 0: 363.566 us/iter\n",
      "[03:26:50] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 1: 363.399 us/iter\n",
      "[03:26:50] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 2: 363.454 us/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed measurement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:26:57] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:65: Op #0 tvmgen_default_fused_nn_conv2d:\n",
      "[03:26:57] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 0: 150.145 us/iter\n",
      "[03:26:57] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 1: 150.122 us/iter\n",
      "[03:26:57] /root/wang/tvm/src/runtime/graph_executor/debug/graph_executor_debug.cc:68: Iteration: 2: 150.237 us/iter\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m#### NEW FUNCTION TO GET THE LAYER RUNTIME\u001b[39;00m\n\u001b[1;32m     86\u001b[0m t_start  \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m---> 87\u001b[0m times \u001b[39m=\u001b[39m debug_g_mod\u001b[39m.\u001b[39;49mrun_individual(\u001b[39m10\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m t_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/wang/tvm/python/tvm/contrib/debugger/debug_executor.py:395\u001b[0m, in \u001b[0;36mGraphModuleDebug.run_individual\u001b[0;34m(self, number, repeat, min_repeat_ms, limit_zero_time_iterations, cooldown_interval_ms, repeats_to_cooldown)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_individual\u001b[39m(\n\u001b[1;32m    350\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    351\u001b[0m     number,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m     repeats_to_cooldown\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    357\u001b[0m ):\n\u001b[1;32m    358\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run each operation in the graph and get the time per op for all ops.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[1;32m    360\u001b[0m \u001b[39m    number: int\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39m    the repeat of the measurement.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_individual(\n\u001b[1;32m    396\u001b[0m         number,\n\u001b[1;32m    397\u001b[0m         repeat,\n\u001b[1;32m    398\u001b[0m         min_repeat_ms,\n\u001b[1;32m    399\u001b[0m         limit_zero_time_iterations,\n\u001b[1;32m    400\u001b[0m         cooldown_interval_ms,\n\u001b[1;32m    401\u001b[0m         repeats_to_cooldown,\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[1;32m    404\u001b[0m     offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/wang/tvm/python/tvm/_ffi/_ctypes/packed_func.py:228\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_val \u001b[39m=\u001b[39m TVMValue()\n\u001b[1;32m    226\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m--> 228\u001b[0m     _LIB\u001b[39m.\u001b[39;49mTVMFuncCall(\n\u001b[1;32m    229\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m    230\u001b[0m         values,\n\u001b[1;32m    231\u001b[0m         tcodes,\n\u001b[1;32m    232\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(num_args),\n\u001b[1;32m    233\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(ret_val),\n\u001b[1;32m    234\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(ret_tcode),\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    237\u001b[0m ):\n\u001b[1;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "measurements = {}\n",
    "a_range = [3]\n",
    "b_range = range(1, 30, 1)\n",
    "for n in a_range:\n",
    "    for i in b_range:\n",
    "        state = i\n",
    "        config[\"c\"] = n\n",
    "        config[\"kernel\"] = i\n",
    "        \n",
    "        #print(config)\n",
    "        # prepare input tensors\n",
    "        repeat = 1024\n",
    "        required = int(config[\"n\"]) * int(config[\"c\"]) * int(config[\"h\"]) * int(config[\"w\"])\n",
    "        '''\n",
    "        inp_shape = (\n",
    "            int(config[\"h\"]),\n",
    "            int(config[\"w\"]),\n",
    "            int(config[\"c\"]),\n",
    "            int(config[\"n\"])\n",
    "        )\n",
    "        '''\n",
    "        inp_shape = (\n",
    "            int(config[\"n\"]),\n",
    "            int(config[\"c\"]),\n",
    "            int(config[\"h\"]),\n",
    "            int(config[\"w\"]),\n",
    "        )\n",
    "        rand_data = np.random.rand(int(np.ceil(required/repeat)))\n",
    "        inp_data = np.repeat(rand_data, repeat)[:required].reshape(inp_shape).astype(\"float32\")\n",
    "        #inp_data = np.random.rand(np.prod(inp_shape)).reshape(inp_shape).astype(\"float32\")\n",
    "\n",
    "        '''\n",
    "        weight_shape = (\n",
    "            int(config[\"kernel\"]),\n",
    "            int(config[\"kernel\"]),\n",
    "            int(config[\"c\"] / config[\"grps\"]),\n",
    "            int(config[\"channels\"]),\n",
    "        )\n",
    "        '''\n",
    "        weight_shape = (\n",
    "            int(config[\"channels\"]),\n",
    "            int(config[\"c\"] / config[\"grps\"]),\n",
    "            int(config[\"kernel\"]),\n",
    "            int(config[\"kernel\"])\n",
    "        )\n",
    "        required = int(config[\"channels\"]) * int(config[\"c\"] / config[\"grps\"]) * int(config[\"kernel\"]) * int(config[\"kernel\"])\n",
    "        rand_data = np.random.rand(int(np.ceil(required/repeat)))\n",
    "        weight_data = np.repeat(rand_data, repeat)[:required].reshape(weight_shape).astype(\"float32\")\n",
    "        #weight_data = np.random.rand(np.prod(weight_shape)).reshape(weight_shape).astype(\"float32\")\n",
    "        x = tvm.relay.var(\"data\", tvm.relay.TensorType(inp_shape), dtype=\"float32\")\n",
    "        y = tvm.relay.Constant(tvm.nd.array(weight_data))\n",
    "\n",
    "        # compile with TVM\n",
    "        expr = conv2d(\n",
    "            data = x,\n",
    "            weight= y,\n",
    "            strides=int(config[\"strides\"]),\n",
    "            padding=int(config[\"pad\"]),\n",
    "            dilation=int(config[\"dilation\"]),\n",
    "            groups=int(config[\"grps\"]),\n",
    "            channels=int(config[\"channels\"]),\n",
    "            kernel_size=int(config[\"kernel\"]),\n",
    "            data_layout=\"NCHW\",\n",
    "            kernel_layout=\"OIHW\",\n",
    "            #data_layout=\"NHWC\",\n",
    "            #kernel_layout=\"HWIO\",\n",
    "        )\n",
    "        \n",
    "        mod = tvm.ir.IRModule.from_expr(expr)\n",
    "        params = {}\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            compiled_graph_lib = tvm.relay.build_module.build(mod, target_class, params=params)\n",
    "\n",
    "        # measuring the execution time\n",
    "        from tvm.contrib.debugger import debug_executor as graph_runtime\n",
    "\n",
    "        ## building runtime\n",
    "        debug_g_mod = graph_runtime.GraphModuleDebug(\n",
    "            compiled_graph_lib[\"debug_create\"](\"default\", dev),\n",
    "            [dev],\n",
    "            compiled_graph_lib.get_graph_json(),\n",
    "            \".\"\n",
    "        )\n",
    "        \n",
    "        #### NEW FUNCTION TO GET THE LAYER RUNTIME\n",
    "        t_start  = time.monotonic()\n",
    "        times = debug_g_mod.run_individual(10, 3, 1000)\n",
    "        t_end = time.monotonic()\n",
    "        \n",
    "        try:\n",
    "            for idx, node in enumerate(debug_g_mod.debug_datum._nodes_list):\n",
    "                if layer_name in node[\"op\"]:\n",
    "                    layer_time = float(times[idx])*1000\n",
    "                    actual_layer_name = node[\"op\"]\n",
    "            # print(1)\n",
    "            print(layer_time, \"ms\")\n",
    "\n",
    "            runs = int(max(1, np.ceil(time_min_res / (layer_time/1000))))\n",
    "\n",
    "            # determine the noise\n",
    "            iterations = 20\n",
    "            powers = []\n",
    "            gpu_utils = []\n",
    "            mem_utils = []\n",
    "            gpu_clocks = []\n",
    "            sm_clocks = []\n",
    "            mem_clocks = []\n",
    "            alloc_memory = []\n",
    "            profile_times = []\n",
    "\n",
    "            # burn in \n",
    "            t_burn_in = 5\n",
    "            t_start = time.monotonic()\n",
    "            t_end = t_start + t_burn_in\n",
    "            while time.monotonic() < t_end:\n",
    "                # run debug runtime without profiling as burn in\n",
    "                with suppress_stdout():\n",
    "                    test_data = debug_g_mod.profile(collectors=[], data=tvm.nd.array(inp_data.astype(\"float32\")), runs=runs)\n",
    "            print(1)\n",
    "            p_start = time.monotonic()\n",
    "            for r in range(0, iterations):        \n",
    "                # reload the Metric Collector due to issues with the PAPI backend\n",
    "                data_collector = tvm.runtime.profiling.PAPIMetricCollector({dev: metrics}, component=\"nvml\")    \n",
    "\n",
    "                # run debug runtime with time measurements only\n",
    "                #with suppress_stdout():\n",
    "                test_data = debug_g_mod.profile(collectors=[data_collector], data=tvm.nd.array(inp_data.astype(\"float32\")), runs=runs)\n",
    "                pstate = nv.nvmlDeviceGetPowerState(handle)\n",
    "                #print(\"\\r\",(r+1),\"PState:\", pstate, end=\"\")\n",
    "\n",
    "                # extract measurement of current run\n",
    "                powers.append(test_data.calls[0][metrics[0]].value)\n",
    "                gpu_utils.append(test_data.calls[0][metrics[1]].value)\n",
    "                mem_utils.append(test_data.calls[0][metrics[2]].value)\n",
    "                gpu_clocks.append(test_data.calls[0][metrics[3]].value)\n",
    "                sm_clocks.append(test_data.calls[0][metrics[4]].value)\n",
    "                mem_clocks.append(test_data.calls[0][metrics[5]].value)\n",
    "                alloc_memory.append(test_data.calls[0][metrics[6]].value)\n",
    "                profile_times.append(test_data.calls[0][\"Duration (us)\"].microseconds/1000000/runs) # in seconds\n",
    "                #time.sleep(1)\n",
    "            print(2)\n",
    "            p_delta = time.monotonic() - p_start\n",
    "            avg_power = np.mean(powers)/1000\n",
    "            max_power = np.max(powers)/1000\n",
    "            min_power = np.min(powers)/1000\n",
    "            std_power = np.std(powers)/1000\n",
    "            #calculate Z-Score\n",
    "            z_scores = ((np.array(powers)/1000) - avg_power)/std_power\n",
    "            cleaned_powers = []\n",
    "            threshold = 0.25\n",
    "            while len(cleaned_powers) < 3:\n",
    "                cleaned_powers = []\n",
    "                threshold += 0.05\n",
    "                for idx, score in enumerate(z_scores):\n",
    "                    if abs(score) < threshold:\n",
    "                        cleaned_powers.append(powers[idx]/1000)\n",
    "            print(3)\n",
    "            layer_power = np.median(cleaned_powers)\n",
    "            layer_memory = np.median(alloc_memory)/(1024**3)\n",
    "\n",
    "            #print()\n",
    "            measurements[state] = (layer_time, layer_power, layer_memory)\n",
    "            print(state, (layer_time, layer_power, layer_memory))\n",
    "            #print()\n",
    "        except:\n",
    "            print(\"failed measurement\")\n",
    "            #measurements[state] = (-1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'op': 'param',\n",
       "  'name': 'data',\n",
       "  'inputs': [],\n",
       "  'attrs': {'T': 'type: float32'},\n",
       "  'shape': [1, 3, 225, 225]},\n",
       " {'op': 'param',\n",
       "  'name': 'p0',\n",
       "  'inputs': [],\n",
       "  'attrs': {'T': 'type: float32'},\n",
       "  'shape': [32, 3, 4, 4]},\n",
       " {'op': 'tvmgen_default_fused_nn_conv2d',\n",
       "  'name': 'tvmgen_default_fused_nn_conv2d',\n",
       "  'attrs': {'num_outputs': '1',\n",
       "   'num_inputs': '2',\n",
       "   'flatten_data': '0',\n",
       "   'func_name': 'tvmgen_default_fused_nn_conv2d',\n",
       "   'out_layout': '',\n",
       "   'data_layout': 'NCHW',\n",
       "   'kernel_layout': 'OIHW',\n",
       "   'hash': '84e7f8ea0e0f2896',\n",
       "   'T': 'type: float32'},\n",
       "  'inputs': ['data', 'p0'],\n",
       "  'shape': [1, 32, 222, 222]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_g_mod.debug_datum._nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
